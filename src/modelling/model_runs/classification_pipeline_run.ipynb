{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# fixing directory to root of project\n",
    "import git\n",
    "import os\n",
    "import sys\n",
    "\n",
    "repo = git.Repo(\".\", search_parent_directories=True)\n",
    "os.chdir(repo.working_tree_dir)\n",
    "sys.path.append(repo.working_tree_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from src.utils.utils import int_loguniform\n",
    "from src.modelling.pipeline.ml_pipeline import (\n",
    "    preprocess_features,\n",
    "    preprocess_target,\n",
    "    FilterFeatures,\n",
    "    model_pipeline,\n",
    "    )\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "50                 7.0               3.2                4.7               1.4   \n",
       "51                 6.4               3.2                4.5               1.5   \n",
       "52                 6.9               3.1                4.9               1.5   \n",
       "53                 5.5               2.3                4.0               1.3   \n",
       "54                 6.5               2.8                4.6               1.5   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "50      1.0  \n",
       "51      1.0  \n",
       "52      1.0  \n",
       "53      1.0  \n",
       "54      1.0  \n",
       "..      ...  \n",
       "145     2.0  \n",
       "146     2.0  \n",
       "147     2.0  \n",
       "148     2.0  \n",
       "149     2.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "iris_data = pd.DataFrame(np.concatenate((iris.data, np.array([iris.target]).T), axis=1), columns=iris.feature_names + ['target'])\n",
    "iris_data = iris_data[iris_data[\"target\"].isin([2.0, 1.0])]\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pipeline code running with a logistic regression and a decision tree classifier model\n",
    "# see where it breaks, remove those bits of code temporarily and get the core pipeline working\n",
    "# build some logic into the broken bits of the code to run differently when a classification task is running, get the code working agian with all bits added back in\n",
    "# code the classification logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available for parallel processing: 4\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=150. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1361.35it/s] \n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 925.08it/s] \n",
      "2025/03/31 16:19:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\mlflow\\sklearn\\utils.py:808: UserWarning: Top 50 child runs will be created based on ordering in rank_test_f1_macro column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/03/31 16:19:02 INFO mlflow.sklearn.utils: Logging the 50 best runs, no runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.01045079]), 'std_fit_time': array([0.00703152]), 'mean_score_time': array([0.00650473]), 'std_score_time': array([0.00863728]), 'params': [{}], 'split0_test_f1_macro': array([1.]), 'split1_test_f1_macro': array([0.87301587]), 'split2_test_f1_macro': array([0.9372549]), 'split3_test_f1_macro': array([1.]), 'split4_test_f1_macro': array([0.9372549]), 'mean_test_f1_macro': array([0.94950514]), 'std_test_f1_macro': array([0.0474346]), 'rank_test_f1_macro': array([1]), 'split0_train_f1_macro': array([0.95311355]), 'split1_train_f1_macro': array([0.96871945]), 'split2_train_f1_macro': array([0.96875]), 'split3_train_f1_macro': array([0.98437118]), 'split4_train_f1_macro': array([0.98437118]), 'mean_train_f1_macro': array([0.97186507]), 'std_train_f1_macro': array([0.01169636]), 'split0_test_accuracy': array([1.]), 'split1_test_accuracy': array([0.875]), 'split2_test_accuracy': array([0.9375]), 'split3_test_accuracy': array([1.]), 'split4_test_accuracy': array([0.9375]), 'mean_test_accuracy': array([0.95]), 'std_test_accuracy': array([0.04677072]), 'rank_test_accuracy': array([1]), 'split0_train_accuracy': array([0.953125]), 'split1_train_accuracy': array([0.96875]), 'split2_train_accuracy': array([0.96875]), 'split3_train_accuracy': array([0.984375]), 'split4_train_accuracy': array([0.984375]), 'mean_train_accuracy': array([0.971875]), 'std_train_accuracy': array([0.01169268])}\n",
      "RandomForestClassifier\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 1 is smaller than n_iter=150. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1168.70it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1310.84it/s]\n",
      "2025/03/31 16:19:18 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"d:\\Users\\sean.ogara\\.conda\\envs\\auto-ml\\Lib\\site-packages\\mlflow\\sklearn\\utils.py:808: UserWarning: Top 50 child runs will be created based on ordering in rank_test_f1_macro column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/03/31 16:19:18 INFO mlflow.sklearn.utils: Logging the 50 best runs, no runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.18897462]), 'std_fit_time': array([0.05190701]), 'mean_score_time': array([0.00941982]), 'std_score_time': array([0.00247217]), 'params': [{}], 'split0_test_f1_macro': array([1.]), 'split1_test_f1_macro': array([0.87301587]), 'split2_test_f1_macro': array([0.875]), 'split3_test_f1_macro': array([0.875]), 'split4_test_f1_macro': array([0.9372549]), 'mean_test_f1_macro': array([0.91205415]), 'std_test_f1_macro': array([0.05027834]), 'rank_test_f1_macro': array([1]), 'split0_train_f1_macro': array([1.]), 'split1_train_f1_macro': array([1.]), 'split2_train_f1_macro': array([1.]), 'split3_train_f1_macro': array([1.]), 'split4_train_f1_macro': array([1.]), 'mean_train_f1_macro': array([1.]), 'std_train_f1_macro': array([0.]), 'split0_test_accuracy': array([1.]), 'split1_test_accuracy': array([0.875]), 'split2_test_accuracy': array([0.875]), 'split3_test_accuracy': array([0.875]), 'split4_test_accuracy': array([0.9375]), 'mean_test_accuracy': array([0.9125]), 'std_test_accuracy': array([0.05]), 'rank_test_accuracy': array([1]), 'split0_train_accuracy': array([1.]), 'split1_train_accuracy': array([1.]), 'split2_train_accuracy': array([1.]), 'split3_train_accuracy': array([1.]), 'split4_train_accuracy': array([1.]), 'mean_train_accuracy': array([1.]), 'std_train_accuracy': array([0.])}\n"
     ]
    }
   ],
   "source": [
    "# target variables\n",
    "target_var_list = [\"target\"]\n",
    "# drop any unecessary variables from the model. In this case, we are dropping the geographical identifier.\n",
    "drop_variables = []\n",
    "# model dictionary and hyperparameter search space\n",
    "model_param_dict = {\n",
    "    LogisticRegression(): {},\n",
    "    RandomForestClassifier(): {}\n",
    "}\n",
    "# optional controls:\n",
    "# select features list - use to subset specific features of interest, if blank it will use all features.\n",
    "# change feature_filter__filter_features hyperparam when using this\n",
    "select_features_list = []\n",
    "# optional - user specified model for evaluation plots. e.g. user_model = \"Lasso\"\n",
    "# if left blank out the best performing model will be used for the evaluation plots\n",
    "user_model = \"\"\n",
    "# shortened feature name label for evaluation plots\n",
    "col_labels = {}\n",
    "\n",
    "# run pipeline for all models\n",
    "for target_var in target_var_list:\n",
    "    # pre-processing\n",
    "    # drop cols, convert to set to drop unique cols only\n",
    "    cols_to_drop = list(set([target_var] + drop_variables))\n",
    "    features = preprocess_features(df=iris_data, cols_to_drop=cols_to_drop)\n",
    "    target_df = preprocess_target(df=iris_data, target_col=target_var)\n",
    "\n",
    "    # run model pipeline\n",
    "    model_pipeline(\n",
    "        model_param_dict=model_param_dict,\n",
    "        target_var=target_var,\n",
    "        target_df=target_df,\n",
    "        feature_df=features,\n",
    "        id_col=\"\",\n",
    "        original_df=iris_data,\n",
    "        output_path=\"outputs\",\n",
    "        output_label=\"classification_demo\",\n",
    "        col_label_map=col_labels,\n",
    "        user_evaluation_model=user_model,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
